{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Loading Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz](http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textGraph = \"models/tensorflow/mask_rcnn_inception_v2_coco_2018_01_28.pbtxt\"\n",
    "modelWeights = \"models/tensorflow/mask_rcnn_frozen_inference_graph.pb\"\n",
    "\n",
    "# Load the network\n",
    "net = cv2.dnn.readNetFromTensorflow(modelWeights, textGraph);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Initialize The Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confThreshold = 0.5  # Confidence threshold\n",
    "maskThreshold = 0.3  # Mask threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the predicted bounding box, colorize and show the mask on the image\n",
    "def drawBox(frame, classId, conf, left, top, right, bottom, classMask):\n",
    "    # Draw a bounding box.\n",
    "    cv2.rectangle(frame, (left, top), (right, bottom), (255, 178, 50), 3)\n",
    "    \n",
    "    # Print a label of class.\n",
    "    label = '%.2f' % conf\n",
    "    if classes:\n",
    "        assert(classId < len(classes))\n",
    "        label = '%s:%s' % (classes[classId], label)\n",
    "    \n",
    "    # Display the label at the top of the bounding box\n",
    "    labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    top = max(top, labelSize[1])\n",
    "    cv2.rectangle(frame, (left, top - round(1.5*labelSize[1])), (left + round(1.5*labelSize[0]), top + baseLine), (255, 255, 255), cv2.FILLED)\n",
    "    cv2.putText(frame, label, (left, top), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,0), 1)\n",
    "\n",
    "    # Resize the mask, threshold, color and apply it on the image\n",
    "    classMask = cv2.resize(classMask, (right - left + 1, bottom - top + 1))\n",
    "    mask = (classMask > maskThreshold)\n",
    "    roi = frame[top:bottom+1, left:right+1][mask]\n",
    "\n",
    "    # color = colors[classId%len(colors)]\n",
    "    # Comment the above line and uncomment the two lines below to generate different instance colors\n",
    "    colorIndex = random.randint(0, len(colors)-1)\n",
    "    color = colors[colorIndex]\n",
    "\n",
    "    frame[top:bottom+1, left:right+1][mask] = ([0.3*color[0], 0.3*color[1], 0.3*color[2]] + 0.7 * roi).astype(np.uint8)\n",
    "\n",
    "    # Draw the contours on the image\n",
    "    mask = mask.astype(np.uint8)\n",
    "    contours, hierarchy = cv2.findContours(mask,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(frame[top:bottom+1, left:right+1], contours, -1, color, 3, cv2.LINE_8, hierarchy, 100)\n",
    "\n",
    "# For each frame, extract the bounding box and mask for each detected object\n",
    "def postprocess(boxes, masks):\n",
    "    # Output size of masks is NxCxHxW where\n",
    "    # N - number of detected boxes\n",
    "    # C - number of classes (excluding background)\n",
    "    # HxW - segmentation shape\n",
    "    numClasses = masks.shape[1]\n",
    "    numDetections = boxes.shape[2]\n",
    "\n",
    "    frameH = frame.shape[0]\n",
    "    frameW = frame.shape[1]\n",
    "\n",
    "    for i in range(numDetections):\n",
    "        box = boxes[0, 0, i]\n",
    "        mask = masks[i]\n",
    "        score = box[2]\n",
    "        if score > confThreshold:\n",
    "            classId = int(box[1])\n",
    "            \n",
    "            # Extract the bounding box\n",
    "            left = int(frameW * box[3])\n",
    "            top = int(frameH * box[4])\n",
    "            right = int(frameW * box[5])\n",
    "            bottom = int(frameH * box[6])\n",
    "            \n",
    "            left = max(0, min(left, frameW - 1))\n",
    "            top = max(0, min(top, frameH - 1))\n",
    "            right = max(0, min(right, frameW - 1))\n",
    "            bottom = max(0, min(bottom, frameH - 1))\n",
    "            \n",
    "            # Extract the mask for the object\n",
    "            classMask = mask[classId]\n",
    "\n",
    "            # Draw bounding box, colorize and show the mask on the image\n",
    "            drawBox(frame, classId, score, left, top, right, bottom, classMask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- Loading Names of Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load names of classes\n",
    "classesFile = \"model/tensorflow/mscoco_labels.names\";\n",
    "\n",
    "classes = None\n",
    "\n",
    "with open(classesFile, 'rt') as f:\n",
    "    classes = f.read().rstrip('\\n').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6- Random Colors to Display in the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classes\n",
    "colorsFile = \"colors.txt\";\n",
    "\n",
    "with open(colorsFile, 'rt') as f:\n",
    "    colorsStr = f.read().rstrip('\\n').split('\\n')\n",
    "colors = [] #[0,0,0]\n",
    "\n",
    "for i in range(len(colorsStr)):\n",
    "    rgb = colorsStr[i].split(' ')\n",
    "    color = np.array([float(rgb[0]), float(rgb[1]), float(rgb[2])])\n",
    "    colors.append(color)\n",
    "    \n",
    "colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7- Testing on Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "frame= cv2.imread(\"images/pedestrian.jpg\")\n",
    "\n",
    "# Create a 4D blob from a frame.\n",
    "blob = cv2.dnn.blobFromImage(frame, swapRB=True, crop=False)\n",
    "\n",
    "# Set the input to the network\n",
    "net.setInput(blob)\n",
    "\n",
    "# Run the forward pass to get output from the output layers\n",
    "boxes, masks = net.forward(['detection_out_final', 'detection_masks'])\n",
    "\n",
    "# Extract the bounding box and mask for each of the detected objects\n",
    "postprocess(boxes, masks)\n",
    "\n",
    "plt.figure(figsize=[10,10])\n",
    "plt.imshow(frame[...,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "frame= cv2.imread(\"images/input.jpg\")\n",
    "\n",
    "# Create a 4D blob from a frame.\n",
    "blob = cv2.dnn.blobFromImage(frame, swapRB=True, crop=False)\n",
    "\n",
    "# Set the input to the network\n",
    "net.setInput(blob)\n",
    "\n",
    "# Run the forward pass to get output from the output layers\n",
    "boxes, masks = net.forward(['detection_out_final', 'detection_masks'])\n",
    "\n",
    "# Extract the bounding box and mask for each of the detected objects\n",
    "postprocess(boxes, masks)\n",
    "\n",
    "plt.figure(figsize=[10,10])\n",
    "plt.imshow(frame[...,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "frame= cv2.imread(\"images/alireza-in-workshop.jpg\")\n",
    "\n",
    "# Create a 4D blob from a frame.\n",
    "blob = cv2.dnn.blobFromImage(frame, swapRB=True, crop=False)\n",
    "\n",
    "# Set the input to the network\n",
    "net.setInput(blob)\n",
    "\n",
    "# Run the forward pass to get output from the output layers\n",
    "boxes, masks = net.forward(['detection_out_final', 'detection_masks'])\n",
    "\n",
    "# Extract the bounding box and mask for each of the detected objects\n",
    "postprocess(boxes, masks)\n",
    "\n",
    "plt.figure(figsize=[10,10])\n",
    "plt.imshow(frame[...,::-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
