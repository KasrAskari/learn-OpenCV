{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Setting up Face Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(input, faces, thickness=2):\n",
    "    if faces[1] is not None:\n",
    "        for idx, face in enumerate(faces[1]):\n",
    "            coords = face[:-1].astype(np.int32)\n",
    "            cv2.rectangle(input, (coords[0], coords[1]), (coords[0]+coords[2], coords[1]+coords[3]), (0, 255, 0), thickness)\n",
    "            cv2.circle(input, (coords[4], coords[5]), 2, (255, 0, 0), thickness)\n",
    "            cv2.circle(input, (coords[6], coords[7]), 2, (0, 0, 255), thickness)\n",
    "            cv2.circle(input, (coords[8], coords[9]), 2, (0, 255, 0), thickness)\n",
    "            cv2.circle(input, (coords[10], coords[11]), 2, (255, 0, 255), thickness)\n",
    "            cv2.circle(input, (coords[12], coords[13]), 2, (0, 255, 255), thickness)\n",
    "\n",
    "\n",
    "detector = cv2.FaceDetectorYN.create(\n",
    "    \"models/face/face_detection_yunet_2022mar.onnx\",\n",
    "    \"\",\n",
    "    (320, 320),\n",
    "    0.8,\n",
    "    0.3,\n",
    "    5000\n",
    ")\n",
    "\n",
    "image1 = cv2.imread(\"images/akhavan.jpg\")\n",
    "img1 = image1.copy()\n",
    "img1Width = int(img1.shape[1])\n",
    "img1Height = int(img1.shape[0])\n",
    "img1 = cv2.resize(img1, (img1Width, img1Height))\n",
    "\n",
    "detector.setInputSize((img1Width, img1Height))\n",
    "faces1 = detector.detect(img1)\n",
    "\n",
    "assert faces1[1] is not None, 'Cannot find a face in {}'.format(args.image1)\n",
    "# Draw results on the input image\n",
    "visualize(img1, faces1)\n",
    "# Save results if save is true\n",
    "\n",
    "image2 = cv2.imread(\"images/alireza-in-workshop.jpg\")\n",
    "img2 = image2.copy()\n",
    "\n",
    "\n",
    "detector.setInputSize((img2.shape[1], img2.shape[0]))\n",
    "faces2 = detector.detect(img2)\n",
    "assert faces2[1] is not None, 'Cannot find a face in {}'.format(args.image2)\n",
    "visualize(img2, faces2)\n",
    "\n",
    "plt.figure(figsize=[24,8])\n",
    "plt.subplot(1,2,1);plt.imshow(img1[...,::-1]);plt.title(\"Image1\");\n",
    "plt.subplot(1,2,2);plt.imshow(img2[...,::-1]);plt.title(\"Image2\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Align Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer = cv2.FaceRecognizerSF.create(\n",
    "\"model/face/face_recognition_sface_2021dec.onnx\",\"\")\n",
    "\n",
    "face1_align = recognizer.alignCrop(image1, faces1[1][0])\n",
    "face2_align = recognizer.alignCrop(image2, faces2[1][0])\n",
    "\n",
    "plt.figure(figsize=[10,8])\n",
    "plt.subplot(1,2,1);plt.imshow(face1_align[...,::-1]);plt.title(\"face1\");\n",
    "plt.subplot(1,2,2);plt.imshow(face2_align[...,::-1]);plt.title(\"face2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face1_feature = recognizer.feature(face1_align)\n",
    "face2_feature = recognizer.feature(face2_align)\n",
    "\n",
    "print(face1_feature.shape)\n",
    "print(face2_feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- Finding Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- FaceRecognizerSF_FR_NORM_L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_similarity_threshold = 1.128\n",
    "\n",
    "l2_score = recognizer.match(face1_feature, face2_feature, cv2.FaceRecognizerSF_FR_NORM_L2)\n",
    "\n",
    "msg = 'different identities'\n",
    "if l2_score <= l2_similarity_threshold:\n",
    "    msg = 'the same identity'\n",
    "    \n",
    "print('They have {}. NormL2 Distance: {}, threshold: {} (lower value means higher similarity, min 0.0).'.format(msg, l2_score, l2_similarity_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- FaceRecognizerSF_FR_COSINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_threshold = 0.363\n",
    "\n",
    "cosine_score = recognizer.match(face1_feature, face2_feature, cv2.FaceRecognizerSF_FR_COSINE)\n",
    "\n",
    "msg = 'different identities'\n",
    "if cosine_score >= cosine_similarity_threshold:\n",
    "    msg = 'the same identity'\n",
    "    \n",
    "print('They have {}. Cosine Similarity: {}, threshold: {} (higher value means higher similarity, max 1.0).'.format(msg, cosine_score, cosine_similarity_threshold))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
