{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields](https://openaccess.thecvf.com/content_cvpr_2017/papers/Cao_Realtime_Multi-Person_2D_CVPR_2017_paper.pdf)\n",
    "\n",
    "[Models](https://github.com/CMU-Perceptual-Computing-Lab/openpose/tree/master/models/pose/mpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "protoFile = \"models/caffe/pose_deploy_linevec_faster_4_stages.prototxt\"\n",
    "weightsFile = \"models/caffe/pose_iter_160000.caffemodel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nPoints = 15\n",
    "POSE_PAIRS = [[0,1], [1,2], [2,3], [3,4], [1,5], [5,6], [6,7], [1,14], [14,8], [8,9], [9,10], [14,11], [11,12], [12,13] ]\n",
    "\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Loading Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"images/Tiger_Woods.png\")\n",
    "height, width, _ = image.shape\n",
    "\n",
    "plt.imshow(image[...,::-1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Converting Image to Blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = cv2.dnn.blobFromImage(image, 1.0 / 255, (368, 368), (0, 0, 0), swapRB=False, crop=False)\n",
    "\n",
    "net.setInput(blob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- Run Interface (forward pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward Pass\n",
    "output = net.forward()\n",
    "\n",
    "#Display probability maps\n",
    "plt.figure(figsize=(20,5))\n",
    "for i in range(nPoints):\n",
    "    probMap = output[0, i, :, :]\n",
    "    displayMap = cv2.resize(probMap, (width, height), cv2.INTER_LINEAR)\n",
    "    plt.subplot(2, 8, i+1); plt.axis('off'); plt.imshow(displayMap, cmap='jet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6- Extarct Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and Y Scale\n",
    "scaleX = width / output.shape[3]\n",
    "scaleY = height / output.shape[2]\n",
    "\n",
    "# Empty list to store the detected keypoints\n",
    "points = []\n",
    "\n",
    "# Treshold \n",
    "threshold = 0.1\n",
    "\n",
    "for i in range(nPoints):\n",
    "    # Obtain probability map\n",
    "    probMap = output[0, i, :, :]\n",
    "    \n",
    "    # Find global maxima of the probMap.\n",
    "    _, prob, _, point = cv2.minMaxLoc(probMap)\n",
    "    \n",
    "    # Scale the point to fit on the original image\n",
    "    x = scaleX * point[0]\n",
    "    y = scaleY * point[1]\n",
    "\n",
    "    if prob > threshold : \n",
    "        # Add the point to the list if the probability is greater than the threshold\n",
    "        points.append((int(x), int(y)))\n",
    "    else :\n",
    "        points.append(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7- Display Points & Skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imPoints = image.copy()\n",
    "imSkeleton = image.copy()\n",
    "# Draw points\n",
    "for i, p in enumerate(points):\n",
    "    cv2.circle(imPoints, p, 8, (255, 255,0), thickness=-1, lineType=cv2.FILLED)\n",
    "    cv2.putText(imPoints, \"{}\".format(i), p, cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, lineType=cv2.LINE_AA)\n",
    "\n",
    "# Draw skeleton\n",
    "for pair in POSE_PAIRS:\n",
    "    partA = pair[0]\n",
    "    partB = pair[1]\n",
    "\n",
    "    if points[partA] and points[partB]:\n",
    "        cv2.line(imSkeleton, points[partA], points[partB], (255, 255,0), 2)\n",
    "        cv2.circle(imSkeleton, points[partA], 8, (255, 0, 0), thickness=-1, lineType=cv2.FILLED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,50))\n",
    "plt.subplot(121); plt.axis('off'); plt.imshow(imPoints[...,::-1]);\n",
    "plt.subplot(122); plt.axis('off'); plt.imshow(imSkeleton[...,::-1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Another Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = cv2.imread(\"images/volleyball.jpg\")\n",
    "\n",
    "protoFile = \"model/caffe/pose_deploy_linevec_faster_4_stages.prototxt\"\n",
    "weightsFile = \"model/caffe/pose_iter_160000.caffemodel\"\n",
    "\n",
    "nPoints = 15\n",
    "POSE_PAIRS = [[0,1], [1,2], [2,3], [3,4], [1,5], [5,6], [6,7], [1,14], [14,8], [8,9], [9,10], [14,11], [11,12], [12,13] ]\n",
    "\n",
    "# Load model and Forward Pass\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "blob = cv2.dnn.blobFromImage(image, 1.0 / 255, (368, 368), (0, 0, 0), swapRB=False, crop=False)\n",
    "net.setInput(blob)\n",
    "output = net.forward()\n",
    "\n",
    "# X and Y Scale\n",
    "height, width, _ = image.shape\n",
    "scaleX = width / output.shape[3]\n",
    "scaleY = height / output.shape[2]\n",
    "\n",
    "# Empty list to store the detected keypoints\n",
    "points = []\n",
    "\n",
    "# Treshold \n",
    "threshold = 0.1\n",
    "\n",
    "for i in range(nPoints):\n",
    "    # Obtain probability map\n",
    "    probMap = output[0, i, :, :]\n",
    "    \n",
    "    # Find global maxima of the probMap.\n",
    "    _, prob, _, point = cv2.minMaxLoc(probMap)\n",
    "    \n",
    "    # Scale the point to fit on the original image\n",
    "    x = scaleX * point[0]\n",
    "    y = scaleY * point[1]\n",
    "\n",
    "    if prob > threshold : \n",
    "        # Add the point to the list if the probability is greater than the threshold\n",
    "        points.append((int(x), int(y)))\n",
    "    else :\n",
    "        points.append(None)\n",
    "\n",
    "# Draw skeleton\n",
    "imSkeleton = image.copy()\n",
    "for pair in POSE_PAIRS:\n",
    "    partA = pair[0]\n",
    "    partB = pair[1]\n",
    "\n",
    "    if points[partA] and points[partB]:\n",
    "        cv2.line(imSkeleton, points[partA], points[partB], (255, 255,0), 2)\n",
    "        cv2.circle(imSkeleton, points[partA], 8, (255, 0, 0), thickness=-1, lineType=cv2.FILLED)\n",
    "\n",
    "plt.imshow(imSkeleton[...,::-1]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
